# HistoryQuest-Arabic-Question-Answering-in-Egyptian-History-with-LLM-Fine-Tuning and Transformer-Models.
The project explores how large language models (LLMs), and transformers can improve the way we answer questions about Egyptian history in Arabic. Using models like AraBERTv2 and LLaMa-2 & 3. This work shows how modern technology can make understanding Egypt's rich history easier and more accessible.
# Introduction
This repository comprises three primary Python notebooks, each showcasing the application of advanced machine learning models to historical datasets. The featured models include fine-tuned versions of the Llama 2 and Llama 3 models, along with a Retrieval-Augmented Generation (RAG) system.


# Notebook (1): Llama 2 Model
The first notebook illustrates the use of the Llama 2 model, which is fine-tuned on specific historical datasets. This model aims to deliver precise and insightful analyses of the data, highlighting key historical trends and patterns.
# Features:
•	Data preprocessing and cleaning
•	Model training and fine-tuning
•	Analysis and contextual generation



